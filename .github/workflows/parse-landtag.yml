name: Parse Landtag PDF

on:
  workflow_dispatch:
    inputs:
      pdf_url:
        description: "PDF-URL (leer lassen, wenn URLs-Liste genutzt wird)"
        required: false
        type: string
      list_file:
        description: "Pfad zur URLs-Liste im Repo (eine URL pro Zeile)"
        required: false
        default: "scripts/urls.txt"
        type: string
      force_download:
        description: "PDF(s) immer neu laden"
        required: false
        default: true
        type: boolean
      commit_results:
        description: "Ergebnisse committen/PR erstellen"
        required: false
        default: false
        type: boolean
      target_branch:
        description: "Branch für Commit/PR (nur wenn commit_results=true)"
        required: false
        default: "automation/parsed-sessions"
        type: string

permissions:
  contents: write
  pull-requests: write

concurrency:
  group: parse-landtag
  cancel-in-progress: false

jobs:
  parse:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y jq
          python -m pip install -U pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pdfplumber requests jsonschema
          fi
          python --version

      - name: Prepare output dir
        shell: bash
        run: |
          set -euo pipefail
          rm -rf data || true
          mkdir -p data
          # PDF-Cache nur löschen, wenn force_download=true
          if [ "${{ inputs.force_download }}" = "true" ]; then
            rm -rf .cache/pdfs || true
          fi

      - name: Detect parser script path
        id: detect
        shell: bash
        run: |
          set -euo pipefail
          detected=""
          if [ -f "parse_landtag_pdf (2).py" ]; then
            detected="parse_landtag_pdf (2).py"
          elif [ -f "scripts/parse_landtag_pdf.py" ]; then
            detected="scripts/parse_landtag_pdf.py"
          elif [ -f "parse_landtag_pdf.py" ]; then
            detected="parse_landtag_pdf.py"
          else
            echo "::error::Parser-Skript nicht gefunden. Lege es unter scripts/parse_landtag_pdf.py an."
            exit 1
          fi
          echo "script=${detected}" >> "$GITHUB_OUTPUT"
          echo "Detected script: ${detected}"

      - name: Run parser (always to data/)
        env:
          PYTHONPATH: ${{ github.workspace }}:${{ github.workspace }}/scripts:${{ github.workspace }}/parser_core
        shell: bash
        run: |
          set -euo pipefail
          FORCE_FLAG=""
          if [ "${{ inputs.force_download }}" = "true" ]; then
            FORCE_FLAG="--force-download"
          fi
          if [ -n "${{ inputs.pdf_url }}" ]; then
            echo "Parse single URL -> data/: ${{ inputs.pdf_url }}"
            python "${{ steps.detect.outputs.script }}" --single-url "${{ inputs.pdf_url }}" --out-dir data ${FORCE_FLAG}
          else
            if [ ! -f "${{ inputs.list_file }}" ]; then
              echo "::error::URLs-Liste nicht gefunden: ${{ inputs.list_file }}"
              exit 1
            fi
            echo "Parse list file -> data/: ${{ inputs.list_file }}"
            python "${{ steps.detect.outputs.script }}" --list-file "${{ inputs.list_file }}" --out-dir data ${FORCE_FLAG}
          fi
          echo "Fertig. Dateien in data/:"
          ls -lah data || true

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: parsed-session-${{ github.run_id }}
          path: |
            data/session_*.json
            data/session_*.layout.json
          if-no-files-found: warn
          retention-days: 7

      - name: "Quick sanity: writes to data/"
        shell: bash
        run: |
          set -euo pipefail
          if ls -1 data/session_*.json >/dev/null 2>&1; then
            echo "OK: JSON in data/ vorhanden."
          else
            echo "::error::Keine Session-JSON in data/ gefunden."
            exit 1
          fi

      - name: Stage generated files (force)
        if: ${{ inputs.commit_results == true }}
        shell: bash
        run: |
          set -euo pipefail
          git status --porcelain
          git add -f data/**
          git status --porcelain

      - name: Create PR with results (optional)
        if: ${{ inputs.commit_results == true }}
        uses: peter-evans/create-pull-request@v6
        with:
          branch: ${{ inputs.target_branch }}
          title: "Automated: Parsed Landtag sessions"
          commit-message: "Add/update parsed session outputs (JSON + layout) in data/"
          body: |
            Automated run of Parse Landtag PDF.
            Outputs are always written to data/.
            Included:
            - data/session_*.json (speeches, toc)
            - data/session_*.layout.json (normalized_pages + layout metadata)
          add-paths: |
            data/**
